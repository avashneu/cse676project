{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fnn = nn.Sequential(\n",
    "            nn.BatchNorm1d(42632),\n",
    "            nn.Linear(42632,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,86),\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.fnn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier =  Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset from DDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Obtaining Dataset\n",
    "from tdc.multi_pred import DDI\n",
    "data = DDI(name = 'DrugBank')\n",
    "split = data.get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove all the data that are not present in our encoded molecular formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "mol_dataset_dir = os.path.join(os.path.join(os.getcwd()), 'image_encoded_data')\n",
    "all_filenames = os.listdir(mol_dataset_dir)\n",
    "all_encoded = set([x.split(\".\")[0].strip() for x in all_filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_be_removed = []\n",
    "for count, value in split[\"train\"].iterrows():\n",
    "    if(value[\"Drug1_ID\"]not in all_encoded or value[\"Drug2_ID\"]not in all_encoded):\n",
    "        rows_to_be_removed.append(count)\n",
    "split[\"train\"].drop(rows_to_be_removed,inplace=True)\n",
    "\n",
    "rows_to_be_removed = []\n",
    "for count, value in split[\"test\"].iterrows():\n",
    "    if(value[\"Drug1_ID\"]not in all_encoded or value[\"Drug2_ID\"]not in all_encoded):\n",
    "        rows_to_be_removed.append(count)\n",
    "split[\"test\"].drop(rows_to_be_removed,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "class Classifier_Data_Loader(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f1 = np.array(chem_to_feature_map[self.data.iloc[idx,0]])\n",
    "        f2 = np.array(chem_to_feature_map[self.data.iloc[idx,1]])\n",
    "        f = torch.from_numpy(np.concatenate([f1,f2],axis = 0))\n",
    "        l = self.data.iloc[idx,2]\n",
    "        return f,l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dataset for training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodedDrugData(Dataset):\n",
    "    def __init__(self, setname ):\n",
    "        self.setname = setname\n",
    "        assert setname in ['train','test']\n",
    "        self.overall_dataset_dir = os.path.join(os.path.join(os.getcwd()), 'image_encoded_data')\n",
    "        self.all_filenames = os.listdir(self.overall_dataset_dir)\n",
    "        split[self.setname].reset_index()\n",
    "        self.iter_data = split[self.setname]\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(split[self.setname])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        current_data  = self.iter_data.iloc[idx,:]\n",
    "        drug1 = torch.load(self.overall_dataset_dir+\"/\"+current_data[\"Drug1_ID\"]+\".pt\")\n",
    "        drug2 = torch.load(self.overall_dataset_dir+\"/\"+current_data[\"Drug2_ID\"]+\".pt\")\n",
    "        sample = {'data':torch.stack((drug1,drug2)).flatten(), #preprocessed image, for input into NN\n",
    "                  'label':torch.tensor(current_data[\"Y\"]-1),\n",
    "                  'img_idx':idx}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_drug_data = EncodedDrugData(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Samples from the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': tensor([ 0.3689,  0.3689,  0.3689,  ..., -0.9818, -0.9818, -0.9818],\n",
       "        grad_fn=<ReshapeAliasBackward0>),\n",
       " 'label': tensor(0),\n",
       " 'img_idx': 0}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_encoded_drug_data  = iter(encoded_drug_data)\n",
    "next(iter_encoded_drug_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classifier_train = EncodedDrugData(\"train\")\n",
    "data_classifier_test = EncodedDrugData(\"test\")\n",
    "\n",
    "data_train = DataLoader(data_classifier_train, batch_size = 1024, shuffle = True)\n",
    "data_test = DataLoader(data_classifier_test, batch_size = 38362, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation using CrossEntropy Loss function\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr = 1e-2)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted, actual):\n",
    "    accuracy = 0 \n",
    "    predicted = predicted.detach().numpy()\n",
    "    actual = actual.detach().numpy()\n",
    "    print('1',np.argmax(predicted,axis = 1).shape)\n",
    "    print('2',(np.argmax(predicted,axis = 1) == actual).shape)\n",
    "    x =  (np.argmax(predicted,axis = 1) == actual).sum()/len(predicted)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 42632])\n",
      "tensor([46, 59, 48,  ..., 48, 46, 71])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([46, 15, 69,  ..., 48, 48, 48])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([48, 20, 48,  ..., 48, 72, 34])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([48, 52, 72,  ..., 72, 69, 48])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([48, 84, 19,  ..., 48, 46, 15])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([74, 69, 26,  ..., 46, 59, 72])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([48, 48, 48,  ...,  3, 46, 72])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([72, 46, 48,  ..., 46, 19, 48])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([46, 48, 48,  ..., 48, 46, 46])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([46, 48,  3,  ..., 52,  8,  3])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([72, 46, 72,  ..., 72, 59, 73])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([69, 46, 72,  ..., 57, 48, 46])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([48, 46, 46,  ..., 46, 70, 59])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([48, 63, 48,  ..., 48, 48,  7])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([48, 69, 48,  ..., 46,  3, 48])\n",
      "output [49 49 49 ... 49 49 49]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([46, 48, 82,  ..., 69, 48, 36])\n",
      "output [48 48 48 ... 48 48 48]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([48,  5, 46,  ..., 46, 72, 46])\n",
      "output [48 48 48 ... 48 48 48]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([48, 72, 74,  ..., 46, 48, 46])\n",
      "output [48 48 48 ... 48 48 48]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([46, 72, 72,  ..., 66, 72, 72])\n",
      "output [48 48 48 ... 48 48 48]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([46, 53, 48,  ..., 48, 48, 48])\n",
      "output [48 48 48 ... 48 48 48]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([48, 48, 48,  ..., 72, 59, 46])\n",
      "output [48 48 48 ... 48 48 48]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([46, 19, 48,  ..., 48, 46,  5])\n",
      "output [48 48 48 ... 48 48 48]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([72, 48, 36,  ..., 48, 59, 46])\n",
      "output [48 48 48 ... 48 48 48]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([48, 48, 48,  ..., 46, 36, 46])\n",
      "output [48 48 48 ... 48 48 48]\n",
      "1 (1024,)\n",
      "2 (1024,)\n",
      "0\n",
      "torch.Size([1024, 42632])\n",
      "tensor([72, 59, 31,  ..., 72, 46, 74])\n",
      "output [48 48 48 ... 48 48 48]\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = []\n",
    "train_accuracy = []\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(data_train):\n",
    "        optimizer.zero_grad()\n",
    "        print((data[\"data\"]).shape)\n",
    "        output = classifier(data[\"data\"])\n",
    "        print((data[\"label\"]))\n",
    "        print(\"output\",np.argmax(output.detach().numpy(),axis=1))\n",
    "        loss = loss_function(output, data[\"label\"])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_accuracy.append(accuracy(output,data[\"label\"]))\n",
    "        print(train_accuracy[-1])\n",
    "\n",
    "\n",
    "    for i, data in enumerate(data_test):\n",
    "        optimizer.zero_grad()\n",
    "        output_test = classifier(data[\"data\"])\n",
    "        test_accuracy.append(accuracy(output_test, data[\"label\"]))\n",
    "    print('Epoch: ',epoch,\"Training accuracy: \",train_accuracy[-1], \"Testing accuracy\",test_accuracy[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79b0c0927cb6563f06861f06031bbe7e94ee093f432ce128a4e15af477fe004f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('anacondaX')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
